"""
dag: ab_testing_fraud_detection
description: a/b —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
–≤–µ—Ä—Å–∏—è: 1.0 (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ simple_training_pipeline.py)
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
try:
    from airflow.sdk import Variable
except ImportError:
    from airflow.models import Variable
from scipy.stats import ttest_ind

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ DAG
default_args = {
    'owner': 'mlops',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def bootstrap_metrics_spark(y_test, y_pred, n_iterations=100):
    """
    bootstrap –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –¥–ª—è pyspark —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    parameters
    ----------
    y_test : array-like
        –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y_pred : array-like  
        –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    n_iterations : int, default=100
        –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π bootstrap
        
    returns
    -------
    scores : pandas.dataframe
        dataframe —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
    """
    from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
    
    np.random.seed(42)
    
    # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy arrays –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    y_test = np.array(y_test) if not isinstance(y_test, np.ndarray) else y_test
    y_pred = np.array(y_pred) if not isinstance(y_pred, np.ndarray) else y_pred
    
    df_bootstrap = pd.DataFrame({
        "y_test": y_test,
        "y_pred": y_pred,
    })
    
    scores = []
    
    print(f"–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è bootstrap –∞–Ω–∞–ª–∏–∑ ({n_iterations} –∏—Ç–µ—Ä–∞—Ü–∏–π)...")
    for i in range(n_iterations):
        sample = df_bootstrap.sample(frac=1.0, replace=True)
        
        try:
            metrics = {
                "F1": f1_score(sample["y_test"], sample["y_pred"]),
                "Precision": precision_score(sample["y_test"], sample["y_pred"]),
                "Recall": recall_score(sample["y_test"], sample["y_pred"]),
                "AUC": roc_auc_score(sample["y_test"], sample["y_pred"])
            }
            scores.append(metrics)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
            continue
    
    print(f"Bootstrap –∑–∞–≤–µ—Ä—à–µ–Ω. –ü–æ–ª—É—á–µ–Ω–æ {len(scores)} –≤–∞–ª–∏–¥–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π")
    return pd.DataFrame(scores)


def statistical_comparison_fraud(scores_base, scores_candidate, alpha=0.01):
    """
    —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π fraud detection
    
    parameters
    ----------
    scores_base : pandas.dataframe
        –º–µ—Ç—Ä–∏–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
    scores_candidate : pandas.dataframe
        –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    alpha : float, default=0.01
        —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
        
    returns
    -------
    results : dict
        —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    results = {}
    
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º F1 –∏ Precision –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    for metric in ['F1', 'Precision']:
        if metric not in scores_base.columns or metric not in scores_candidate.columns:
            print(f"–º–µ—Ç—Ä–∏–∫–∞ {metric} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
            
        t_stat, pvalue = ttest_ind(scores_base[metric], scores_candidate[metric])
        
        # —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (cohen's d) —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        pooled_std = np.sqrt((scores_base[metric].var() + scores_candidate[metric].var()) / 2)
        improvement = scores_candidate[metric].mean() - scores_base[metric].mean()
        
        if pooled_std == 0 or np.isnan(pooled_std):
            effect_size = 0.0  # –ù–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∞ –µ—Å–ª–∏ –Ω–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
        else:
            effect_size = abs(improvement) / pooled_std
        
        # –ó–∞—â–∏—Ç–∞ –æ—Ç NaN –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–∞—Ö
        if np.isnan(t_stat):
            t_stat = 0.0
        if np.isnan(pvalue):
            pvalue = 1.0  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ: –Ω–µ—Ç –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
            
        is_significant = pvalue < alpha
        
        results[metric] = {
            't_statistic': t_stat,
            'p_value': pvalue,
            'effect_size': effect_size,
            'is_significant': is_significant,
            'base_mean': scores_base[metric].mean(),
            'candidate_mean': scores_candidate[metric].mean(),
            'improvement': improvement
        }
        
        print(f"\n{metric} —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {results[metric]['base_mean']:.4f}")
        print(f"  –º–æ–¥–µ–ª—å-–∫–∞–Ω–¥–∏–¥–∞—Ç: {results[metric]['candidate_mean']:.4f}")
        print(f"  —É–ª—É—á—à–µ–Ω–∏–µ: {improvement:+.4f}")
        print(f"  p-value: {pvalue:.6f}")
        print(f"  –∑–Ω–∞—á–∏–º–æ (Œ±={alpha}): {is_significant}")
    
    return results


def train_production_model():
    """
    –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π (production) –º–æ–¥–µ–ª–∏ fraud detection
    """
    import mlflow
    import mlflow.spark
    from pyspark.sql import SparkSession
    from pyspark.ml import Pipeline
    from pyspark.ml.feature import VectorAssembler, StandardScaler
    from pyspark.ml.classification import RandomForestClassifier
    from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
    
    print("=== –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π (production) –º–æ–¥–µ–ª–∏ ===")
    
    # –ø–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ airflow
    S3_ENDPOINT_URL = Variable.get("S3_ENDPOINT_URL")
    S3_ACCESS_KEY = Variable.get("S3_ACCESS_KEY")
    S3_SECRET_KEY = Variable.get("S3_SECRET_KEY")
    CLEAN_DATA_PATH = Variable.get("CLEAN_DATA_PATH")
    MLFLOW_TRACKING_URI = Variable.get("MLFLOW_TRACKING_URI")
    MLFLOW_EXPERIMENT_NAME = Variable.get("MLFLOW_EXPERIMENT_NAME")
    MLFLOW_TRACKING_USERNAME = Variable.get("MLFLOW_TRACKING_USERNAME")
    MLFLOW_TRACKING_PASSWORD = Variable.get("MLFLOW_TRACKING_PASSWORD")
    
    # –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    os.environ["MLFLOW_TRACKING_USERNAME"] = MLFLOW_TRACKING_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = MLFLOW_TRACKING_PASSWORD
    os.environ["AWS_ACCESS_KEY_ID"] = S3_ACCESS_KEY
    os.environ["AWS_SECRET_ACCESS_KEY"] = S3_SECRET_KEY
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    os.environ["AWS_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    
    # –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ mlflow
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
    
    # —Å–æ–∑–¥–∞–Ω–∏–µ spark —Å–µ—Å—Å–∏–∏
    spark = SparkSession.builder \
        .appName("FraudDetection_Production") \
        .config("spark.jars.packages", 
                "org.apache.hadoop:hadoop-aws:3.3.4,"
                "com.amazonaws:aws-java-sdk-bundle:1.12.262") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.endpoint", S3_ENDPOINT_URL) \
        .config("spark.hadoop.fs.s3a.access.key", S3_ACCESS_KEY) \
        .config("spark.hadoop.fs.s3a.secret.key", S3_SECRET_KEY) \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
        .config("spark.hadoop.fs.s3a.aws.credentials.provider", 
                "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider") \
        .config("spark.hadoop.fs.s3a.threads.keepalivetime", "60000") \
        .config("spark.hadoop.fs.s3a.connection.establish.timeout", "30000") \
        .config("spark.hadoop.fs.s3a.connection.timeout", "200000") \
        .config("spark.hadoop.fs.s3a.connection.request.timeout", "200000") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .getOrCreate()
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {CLEAN_DATA_PATH}")
        df = spark.read.parquet(CLEAN_DATA_PATH)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {df.count()}")
        
        # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–ª–æ–≥–∏–∫–∞ –∏–∑ simple_training_pipeline.py)
        target_col = 'tx_fraud'
        
        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        fraud_count = df.filter(df[target_col] == 1).count()
        if fraud_count == 0:
            print("—Å–æ–∑–¥–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤...")
            from pyspark.sql.functions import when, rand
            
            percentile_98 = df.approxQuantile("tx_amount", [0.98], 0.01)[0]
            df_with_rand = df.withColumn("random", rand(seed=42))
            
            df = df_with_rand.withColumn(
                target_col,
                when(
                    (df_with_rand["tx_amount"] > percentile_98) | 
                    (df_with_rand["random"] < 0.005), 1
                ).otherwise(0)
            ).drop("random")
            
            fraud_count = df.filter(df[target_col] == 1).count()
            print(f"—Å–æ–∑–¥–∞–Ω–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤: {fraud_count}")
        
        # —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
        
        # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_cols = [col for col in train_df.columns 
                       if col != target_col and 
                       col != 'transaction_id' and
                       col != 'tx_datetime' and
                       train_df.schema[col].dataType.typeName() != 'string']
        
        print(f"–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(feature_cols)}")
        
        # —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ (–±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_raw")
        scaler = StandardScaler(inputCol="features_raw", outputCol="features", withStd=True, withMean=True)
        classifier = RandomForestClassifier(
            labelCol=target_col, 
            featuresCol="features",
            numTrees=10,  # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            maxDepth=5,
            seed=42
        )
        
        pipeline = Pipeline(stages=[assembler, scaler, classifier])
        
        # –æ–±—É—á–µ–Ω–∏–µ
        with mlflow.start_run(run_name=f"production_model_{datetime.now().strftime('%y%m%d_%H%M')}"):
            print("–æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
            model = pipeline.fit(train_df)
            
            # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = model.transform(test_df)
            
            # –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            evaluator = BinaryClassificationEvaluator(labelCol=target_col, rawPredictionCol="rawPrediction")
            auc = evaluator.evaluate(predictions)
            
            accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol="prediction", metricName="accuracy")
            accuracy = accuracy_evaluator.evaluate(predictions)
            
            f1_evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol="prediction", metricName="f1")
            f1 = f1_evaluator.evaluate(predictions)
            
            print(f"–±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å - auc: {auc:.4f}, f1: {f1:.4f}, accuracy: {accuracy:.4f}")
            
            # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            mlflow.log_metric("auc", auc)
            mlflow.log_metric("f1_score", f1)
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_param("model_type", "production_baseline")
            mlflow.log_param("num_trees", 10)
            mlflow.log_param("max_depth", 5)
            
            # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                mlflow.spark.log_model(model, "fraud_model_production")
                print("–±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ mlflow")
            except Exception as e:
                print(f"–æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            
            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∞/–≤ —Ç–µ—Å—Ç–∞
            y_test_prod = [row[target_col] for row in predictions.select(target_col).collect()]
            y_pred_prod = [row["prediction"] for row in predictions.select("prediction").collect()]
            
            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ airflow (—á–µ—Ä–µ–∑ xcom)
            return {
                "model_metrics": {"auc": auc, "f1_score": f1, "accuracy": accuracy},
                "y_test": y_test_prod,
                "y_pred": y_pred_prod,
                "model_type": "production"
            }
    
    finally:
        spark.stop()


def train_candidate_model():
    """
    –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    """
    import mlflow
    import mlflow.spark
    from pyspark.sql import SparkSession
    from pyspark.ml import Pipeline
    from pyspark.ml.feature import VectorAssembler, StandardScaler
    from pyspark.ml.classification import RandomForestClassifier
    from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
    
    print("=== –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ===")
    
    # –ø–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ airflow
    S3_ENDPOINT_URL = Variable.get("S3_ENDPOINT_URL")
    S3_ACCESS_KEY = Variable.get("S3_ACCESS_KEY")
    S3_SECRET_KEY = Variable.get("S3_SECRET_KEY")
    CLEAN_DATA_PATH = Variable.get("CLEAN_DATA_PATH")
    MLFLOW_TRACKING_URI = Variable.get("MLFLOW_TRACKING_URI")
    MLFLOW_EXPERIMENT_NAME = Variable.get("MLFLOW_EXPERIMENT_NAME")
    MLFLOW_TRACKING_USERNAME = Variable.get("MLFLOW_TRACKING_USERNAME")
    MLFLOW_TRACKING_PASSWORD = Variable.get("MLFLOW_TRACKING_PASSWORD")
    
    # –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    os.environ["MLFLOW_TRACKING_USERNAME"] = MLFLOW_TRACKING_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = MLFLOW_TRACKING_PASSWORD
    os.environ["AWS_ACCESS_KEY_ID"] = S3_ACCESS_KEY
    os.environ["AWS_SECRET_ACCESS_KEY"] = S3_SECRET_KEY
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    os.environ["AWS_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    
    # –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ mlflow
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
    
    # —Å–æ–∑–¥–∞–Ω–∏–µ spark —Å–µ—Å—Å–∏–∏
    spark = SparkSession.builder \
        .appName("FraudDetection_Candidate") \
        .config("spark.jars.packages", 
                "org.apache.hadoop:hadoop-aws:3.3.4,"
                "com.amazonaws:aws-java-sdk-bundle:1.12.262") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.endpoint", S3_ENDPOINT_URL) \
        .config("spark.hadoop.fs.s3a.access.key", S3_ACCESS_KEY) \
        .config("spark.hadoop.fs.s3a.secret.key", S3_SECRET_KEY) \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
        .config("spark.hadoop.fs.s3a.aws.credentials.provider", 
                "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider") \
        .config("spark.hadoop.fs.s3a.threads.keepalivetime", "60000") \
        .config("spark.hadoop.fs.s3a.connection.establish.timeout", "30000") \
        .config("spark.hadoop.fs.s3a.connection.timeout", "200000") \
        .config("spark.hadoop.fs.s3a.connection.request.timeout", "200000") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .getOrCreate()
    
    try:
        # –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—Ç–∞ –∂–µ –ª–æ–≥–∏–∫–∞)
        df = spark.read.parquet(CLEAN_DATA_PATH)
        
        # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target_col = 'tx_fraud'
        fraud_count = df.filter(df[target_col] == 1).count()
        if fraud_count == 0:
            from pyspark.sql.functions import when, rand
            percentile_98 = df.approxQuantile("tx_amount", [0.98], 0.01)[0]
            df_with_rand = df.withColumn("random", rand(seed=42))
            df = df_with_rand.withColumn(
                target_col,
                when(
                    (df_with_rand["tx_amount"] > percentile_98) | 
                    (df_with_rand["random"] < 0.005), 1
                ).otherwise(0)
            ).drop("random")
        
        # —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ—Ç –∂–µ seed –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
        train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
        
        # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_cols = [col for col in train_df.columns 
                       if col != target_col and 
                       col != 'transaction_id' and
                       col != 'tx_datetime' and
                       train_df.schema[col].dataType.typeName() != 'string']
        
        # —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_raw")
        scaler = StandardScaler(inputCol="features_raw", outputCol="features", withStd=True, withMean=True)
        classifier = RandomForestClassifier(
            labelCol=target_col, 
            featuresCol="features",
            numTrees=20,  # –ë–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
            maxDepth=8,   # –ë–æ–ª—å—à–µ –≥–ª—É–±–∏–Ω–∞
            minInstancesPerNode=2,  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
            seed=42
        )
        
        pipeline = Pipeline(stages=[assembler, scaler, classifier])
        
        # –æ–±—É—á–µ–Ω–∏–µ
        with mlflow.start_run(run_name=f"candidate_model_{datetime.now().strftime('%y%m%d_%H%M')}"):
            print("–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞...")
            model = pipeline.fit(train_df)
            
            # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = model.transform(test_df)
            
            # –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            evaluator = BinaryClassificationEvaluator(labelCol=target_col, rawPredictionCol="rawPrediction")
            auc = evaluator.evaluate(predictions)
            
            accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol="prediction", metricName="accuracy")
            accuracy = accuracy_evaluator.evaluate(predictions)
            
            f1_evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol="prediction", metricName="f1")
            f1 = f1_evaluator.evaluate(predictions)
            
            print(f"–º–æ–¥–µ–ª—å-–∫–∞–Ω–¥–∏–¥–∞—Ç - auc: {auc:.4f}, f1: {f1:.4f}, accuracy: {accuracy:.4f}")
            
            # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            mlflow.log_metric("auc", auc)
            mlflow.log_metric("f1_score", f1)
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_param("model_type", "candidate_optimized")
            mlflow.log_param("num_trees", 20)
            mlflow.log_param("max_depth", 8)
            
            # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                mlflow.spark.log_model(model, "fraud_model_candidate")
                print("–º–æ–¥–µ–ª—å-–∫–∞–Ω–¥–∏–¥–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ mlflow")
            except Exception as e:
                print(f"–æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            
            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∞/–≤ —Ç–µ—Å—Ç–∞
            y_test_cand = [row[target_col] for row in predictions.select(target_col).collect()]
            y_pred_cand = [row["prediction"] for row in predictions.select("prediction").collect()]
            
            return {
                "model_metrics": {"auc": auc, "f1_score": f1, "accuracy": accuracy},
                "y_test": y_test_cand,
                "y_pred": y_pred_cand,
                "model_type": "candidate"
            }
    
    finally:
        spark.stop()


def ab_test_fraud_models(**context):
    """
    a/b —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π fraud detection
    """
    print("=== a/b —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π fraud detection ===")
    
    # –ø–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–∞—Å–∫–æ–≤
    ti = context['ti']
    production_results = ti.xcom_pull(task_ids='train_production_model')
    candidate_results = ti.xcom_pull(task_ids='train_candidate_model')
    
    if not production_results or not candidate_results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    
    print("—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏:", production_results['model_metrics'])
    print("—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞:", candidate_results['model_metrics'])
    
    # –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_test_prod = production_results['y_test']
    y_pred_prod = production_results['y_pred']
    y_test_cand = candidate_results['y_test']
    y_pred_cand = candidate_results['y_pred']
    
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
    if len(y_test_prod) != len(y_test_cand):
        print("–≤–Ω–∏–º–∞–Ω–∏–µ: —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤—ã–±–æ—Ä–æ–∫!")
    
    # bootstrap –∞–Ω–∞–ª–∏–∑
    print("\n–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ bootstrap –∞–Ω–∞–ª–∏–∑–∞...")
    prod_bootstrap = bootstrap_metrics_spark(y_test_prod, y_pred_prod, n_iterations=100)
    cand_bootstrap = bootstrap_metrics_spark(y_test_cand, y_pred_cand, n_iterations=100)
    
    print("bootstrap –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏:")
    print(prod_bootstrap.describe())
    
    print("\nbootstrap –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞:")
    print(cand_bootstrap.describe())
    
    # —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\n=== —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ===")
    comparison_results = statistical_comparison_fraud(prod_bootstrap, cand_bootstrap, alpha=0.01)
    
    # –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ 2 –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    f1_results = comparison_results.get('F1', {})
    f1_significant = f1_results.get('is_significant', False)
    f1_improvement = f1_results.get('improvement', 0) > 0
    
    # ‚úÖ 2 –∫—Ä–∏—Ç–µ—Ä–∏—è: —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å + –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
    should_deploy = f1_significant and f1_improvement
    
    print(f"\n{'='*60}")
    print("–∏—Ç–æ–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø–æ a/b —Ç–µ—Å—Ç—É:")
    print(f"{'='*60}")
    print(f"‚úÖ –∫—Ä–∏—Ç–µ—Ä–∏–π 1 - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (Œ±=0.01): {f1_significant}")
    print(f"‚úÖ –∫—Ä–∏—Ç–µ—Ä–∏–π 2 - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ f1: {f1_improvement}")
    print(f"")
    if should_deploy:
        print("üöÄ —Ä–µ—à–µ–Ω–∏–µ: —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –≤ production")
        print("   –º–æ–¥–µ–ª—å-–∫–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")
    else:
        print("‚õî —Ä–µ—à–µ–Ω–∏–µ: –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –≤ production")
        if not f1_improvement:
            print("   –ø—Ä–∏—á–∏–Ω–∞: –º–æ–¥–µ–ª—å-–∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –ø–æ–∫–∞–∑–∞–ª–∞ —É–ª—É—á—à–µ–Ω–∏—è f1")
        elif not f1_significant:
            print("   –ø—Ä–∏—á–∏–Ω–∞: —É–ª—É—á—à–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–Ω–∞—á–∏–º–æ")
    print(f"{'='*60}")
    
    # –ª–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ mlflow
    import mlflow
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è MLflow –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    MLFLOW_TRACKING_URI = Variable.get("MLFLOW_TRACKING_URI")
    MLFLOW_EXPERIMENT_NAME = Variable.get("MLFLOW_EXPERIMENT_NAME")
    MLFLOW_TRACKING_USERNAME = Variable.get("MLFLOW_TRACKING_USERNAME")  
    MLFLOW_TRACKING_PASSWORD = Variable.get("MLFLOW_TRACKING_PASSWORD")
    S3_ACCESS_KEY = Variable.get("S3_ACCESS_KEY")
    S3_SECRET_KEY = Variable.get("S3_SECRET_KEY")
    S3_ENDPOINT_URL = Variable.get("S3_ENDPOINT_URL")
    
    # –í–ê–ñ–ù–û: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –î–û –≤—ã–∑–æ–≤–æ–≤ MLflow
    os.environ["MLFLOW_TRACKING_USERNAME"] = MLFLOW_TRACKING_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = MLFLOW_TRACKING_PASSWORD
    os.environ["AWS_ACCESS_KEY_ID"] = S3_ACCESS_KEY
    os.environ["AWS_SECRET_ACCESS_KEY"] = S3_SECRET_KEY
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    os.environ["AWS_S3_ENDPOINT_URL"] = S3_ENDPOINT_URL
    
    # –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º MLflow —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    try:
        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
        mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
        
        with mlflow.start_run(run_name=f"ab_test_{datetime.now().strftime('%y%m%d_%H%M')}"):
            # –ª–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ NaN)
            for metric, results in comparison_results.items():
                # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–∑–∞–º–µ–Ω—è–µ—Ç NaN –Ω–∞ 0.0)
                def safe_log_metric(key, value):
                    if np.isnan(value) or np.isinf(value):
                        mlflow.log_metric(key, 0.0)
                        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {key} —Å–æ–¥–µ—Ä–∂–∏—Ç NaN/Inf, –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞ 0.0")
                    else:
                        mlflow.log_metric(key, float(value))
                
                safe_log_metric(f"{metric.lower()}_base_mean", results['base_mean'])
                safe_log_metric(f"{metric.lower()}_candidate_mean", results['candidate_mean'])
                safe_log_metric(f"{metric.lower()}_improvement", results['improvement'])
                safe_log_metric(f"{metric.lower()}_p_value", results['p_value'])
                safe_log_metric(f"{metric.lower()}_effect_size", results['effect_size'])
            
            # –ª–æ–≥–∏—Ä—É–µ–º —Ä–µ—à–µ–Ω–∏–µ
            mlflow.log_param("f1_significant", f1_significant)
            mlflow.log_param("f1_improvement_positive", f1_improvement)
            mlflow.log_param("should_deploy", should_deploy)
            mlflow.log_param("decision_criteria", "statistical_significance + positive_improvement")
            mlflow.log_param("alpha", 0.01)
            
        print("—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã a/b —Ç–µ—Å—Ç–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ mlflow")
    
    except Exception as mlflow_error:
        print(f"–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ mlflow: {mlflow_error}")
        print("a/b —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ, –Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ mlflow –ø—Ä–æ–ø—É—â–µ–Ω–æ")
    
    # –£–ø—Ä–æ—â–∞–µ–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è XCom (—É–±–∏—Ä–∞–µ–º –±–æ–ª—å—à–∏–µ –æ–±—ä–µ–∫—Ç—ã)
    simplified_results = {
        "should_deploy": should_deploy,
        "f1_significant": f1_significant,
        "f1_improvement": f1_improvement,
        "f1_base_mean": f1_results.get('base_mean', 0),
        "f1_candidate_mean": f1_results.get('candidate_mean', 0),
        "f1_p_value": f1_results.get('p_value', 1.0),
        "production_f1": production_results['model_metrics']['f1_score'],
        "candidate_f1": candidate_results['model_metrics']['f1_score'],
        "production_auc": production_results['model_metrics']['auc'],
        "candidate_auc": candidate_results['model_metrics']['auc'],
        "decision_reason": "2_criteria_validation"
    }
    
    return simplified_results


# dag –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
with DAG(
    dag_id="ab_testing_fraud_detection",
    default_args=default_args,
    description="a/b —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–π",
    schedule=timedelta(hours=6),  # –∑–∞–ø—É—Å–∫ –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['mlops', 'fraud-detection', 'ab-testing', 'validation'],
) as dag:
    
    # task 1: –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π (production) –º–æ–¥–µ–ª–∏
    train_production_task = PythonOperator(
        task_id="train_production_model",
        python_callable=train_production_model,
        dag=dag,
    )
    
    # Task 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞
    train_candidate_task = PythonOperator(
        task_id="train_candidate_model",
        python_callable=train_candidate_model,
        dag=dag,
    )
    
    # Task 3: A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    ab_test_task = PythonOperator(
        task_id="ab_test_models",
        python_callable=ab_test_fraud_models,
        dag=dag,
    )
    
    # –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
    [train_production_task, train_candidate_task] >> ab_test_task